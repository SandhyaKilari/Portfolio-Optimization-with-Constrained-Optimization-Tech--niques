{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimization with Constrained Optimization Techniques: Balancing Risk and Return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background and Motivation\n",
    "\n",
    "This section provides the context and purpose of the project. It explains the importance of portfolio optimization in financial decision-making and highlights the need for advanced optimization techniques to address the limitations of traditional methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Portfolio optimization is a cornerstone of financial decision-making, aiming to balance the trade-off between maximizing returns and minimizing risks. Traditional methods, such as Markowitz mean-variance optimization, often face challenges in adapting to diverse asset classes and dynamic market conditions. By leveraging advanced optimization techniques, this project explores the use of constrained optimization methods to address these limitations with computational efficiency and adaptability.**\n",
    "\n",
    "#### Research Questions:\n",
    "- How does an advanced constrained optimization approach compare to traditional methods in terms of risk-adjusted performance metrics like the Sharpe Ratio?\n",
    "- Can the optimized portfolio adapt dynamically to changing market conditions, maintaining stability during periods of high volatility?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Methodology\n",
    "\n",
    "This section outlines the steps followed to achieve the project's goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import KFold\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1 Data Collection**\n",
    "\n",
    "Historical price data for diversified assets, such as stocks, bonds, and cryptocurrencies, was fetched using the `yfinance` library. Daily returns were computed for analysis.\n",
    "\n",
    "**Selected Tickers**\n",
    "\n",
    "The portfolio includes a diversified mix of asset classes:\n",
    "\n",
    "- **Stocks**: `AAPL` (Apple), `MSFT` (Microsoft), `GOOGL` (Alphabet).\n",
    "  \n",
    "- **Bonds**: `TLT` (iShares 20+ Year Treasury Bond ETF).\n",
    "\n",
    "- **Commodities**: `GLD` (SPDR Gold Shares), `DBC` (Invesco DB Commodity Index Tracking Fund).\n",
    "\n",
    "- **Real Estate**: `VNQ` (Vanguard Real Estate ETF).\n",
    "\n",
    "- **Cryptocurrencies**: `BTC-USD` (Bitcoin), `ETH-USD` (Ethereum).\n",
    "\n",
    "This selection ensures exposure to a broad range of asset classes, enabling robust diversification and risk management in the portfolio optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  9 of 9 completed\n"
     ]
    }
   ],
   "source": [
    "# Data Collection\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'TLT', 'GLD', 'VNQ', 'BTC-USD', 'ETH-USD', 'DBC'] # Diversified portfolio\n",
    "data = yf.download(tickers, start='2010-01-01', end='2023-01-01', group_by='ticker')\n",
    "\n",
    "# Compute daily returns\n",
    "# Adjust NaN handling explicitly for consistency\n",
    "returns = (\n",
    "  data.loc[:, (tickers, 'Adj Close')]\n",
    "  .pct_change(fill_method=None)\n",
    "  .dropna()\n",
    ")\n",
    "returns.columns = tickers # Flatten MultiIndex for simplicity\n",
    "\n",
    "# Risk-free rate\n",
    "risk_free_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th colspan=\"6\" halign=\"left\">BTC-USD</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MSFT</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">TLT</th>\n",
       "      <th colspan=\"6\" halign=\"left\">VNQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>...</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.620001</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>...</td>\n",
       "      <td>89.580002</td>\n",
       "      <td>89.809998</td>\n",
       "      <td>59.519924</td>\n",
       "      <td>2829100.0</td>\n",
       "      <td>45.220001</td>\n",
       "      <td>45.419998</td>\n",
       "      <td>44.200001</td>\n",
       "      <td>44.549999</td>\n",
       "      <td>24.979658</td>\n",
       "      <td>2408400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.850000</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>30.639999</td>\n",
       "      <td>30.959999</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.389999</td>\n",
       "      <td>59.904362</td>\n",
       "      <td>2841600.0</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>44.580002</td>\n",
       "      <td>43.930000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>24.951632</td>\n",
       "      <td>2054200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>31.080000</td>\n",
       "      <td>30.520000</td>\n",
       "      <td>30.770000</td>\n",
       "      <td>...</td>\n",
       "      <td>89.120003</td>\n",
       "      <td>89.180000</td>\n",
       "      <td>59.102425</td>\n",
       "      <td>4099600.0</td>\n",
       "      <td>44.520000</td>\n",
       "      <td>44.840000</td>\n",
       "      <td>44.299999</td>\n",
       "      <td>44.419998</td>\n",
       "      <td>24.906763</td>\n",
       "      <td>2471200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.629999</td>\n",
       "      <td>30.700001</td>\n",
       "      <td>30.190001</td>\n",
       "      <td>30.450001</td>\n",
       "      <td>...</td>\n",
       "      <td>89.120003</td>\n",
       "      <td>89.330002</td>\n",
       "      <td>59.201794</td>\n",
       "      <td>2793200.0</td>\n",
       "      <td>44.459999</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>43.950001</td>\n",
       "      <td>44.900002</td>\n",
       "      <td>25.175903</td>\n",
       "      <td>2091700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.280001</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>30.240000</td>\n",
       "      <td>30.660000</td>\n",
       "      <td>...</td>\n",
       "      <td>88.760002</td>\n",
       "      <td>89.290001</td>\n",
       "      <td>59.175323</td>\n",
       "      <td>2910700.0</td>\n",
       "      <td>44.810001</td>\n",
       "      <td>44.849998</td>\n",
       "      <td>44.180000</td>\n",
       "      <td>44.570000</td>\n",
       "      <td>24.990868</td>\n",
       "      <td>2682000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>16919.291016</td>\n",
       "      <td>16959.845703</td>\n",
       "      <td>16642.072266</td>\n",
       "      <td>16717.173828</td>\n",
       "      <td>16717.173828</td>\n",
       "      <td>1.574858e+10</td>\n",
       "      <td>238.699997</td>\n",
       "      <td>238.929993</td>\n",
       "      <td>235.830002</td>\n",
       "      <td>236.960007</td>\n",
       "      <td>...</td>\n",
       "      <td>100.010002</td>\n",
       "      <td>100.139999</td>\n",
       "      <td>93.320374</td>\n",
       "      <td>26475700.0</td>\n",
       "      <td>82.709999</td>\n",
       "      <td>82.970001</td>\n",
       "      <td>81.980003</td>\n",
       "      <td>82.709999</td>\n",
       "      <td>76.934006</td>\n",
       "      <td>3961900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>16716.400391</td>\n",
       "      <td>16768.169922</td>\n",
       "      <td>16497.556641</td>\n",
       "      <td>16552.572266</td>\n",
       "      <td>16552.572266</td>\n",
       "      <td>1.700571e+10</td>\n",
       "      <td>236.889999</td>\n",
       "      <td>239.720001</td>\n",
       "      <td>234.169998</td>\n",
       "      <td>234.529999</td>\n",
       "      <td>...</td>\n",
       "      <td>99.349998</td>\n",
       "      <td>99.550003</td>\n",
       "      <td>92.770554</td>\n",
       "      <td>17302900.0</td>\n",
       "      <td>82.879997</td>\n",
       "      <td>83.269997</td>\n",
       "      <td>81.180000</td>\n",
       "      <td>81.300003</td>\n",
       "      <td>75.622467</td>\n",
       "      <td>5168000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>16552.322266</td>\n",
       "      <td>16651.755859</td>\n",
       "      <td>16508.683594</td>\n",
       "      <td>16642.341797</td>\n",
       "      <td>16642.341797</td>\n",
       "      <td>1.447224e+10</td>\n",
       "      <td>235.649994</td>\n",
       "      <td>241.919998</td>\n",
       "      <td>235.649994</td>\n",
       "      <td>241.009995</td>\n",
       "      <td>...</td>\n",
       "      <td>99.790001</td>\n",
       "      <td>100.680000</td>\n",
       "      <td>93.823586</td>\n",
       "      <td>16593000.0</td>\n",
       "      <td>81.870003</td>\n",
       "      <td>83.260002</td>\n",
       "      <td>81.629997</td>\n",
       "      <td>83.080002</td>\n",
       "      <td>77.278168</td>\n",
       "      <td>5398400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>16641.330078</td>\n",
       "      <td>16643.427734</td>\n",
       "      <td>16408.474609</td>\n",
       "      <td>16602.585938</td>\n",
       "      <td>16602.585938</td>\n",
       "      <td>1.592916e+10</td>\n",
       "      <td>238.210007</td>\n",
       "      <td>239.960007</td>\n",
       "      <td>236.660004</td>\n",
       "      <td>239.820007</td>\n",
       "      <td>...</td>\n",
       "      <td>99.370003</td>\n",
       "      <td>99.559998</td>\n",
       "      <td>92.779854</td>\n",
       "      <td>20810200.0</td>\n",
       "      <td>82.480003</td>\n",
       "      <td>82.849998</td>\n",
       "      <td>81.500000</td>\n",
       "      <td>82.480003</td>\n",
       "      <td>76.720062</td>\n",
       "      <td>4897700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>16603.673828</td>\n",
       "      <td>16628.986328</td>\n",
       "      <td>16517.519531</td>\n",
       "      <td>16547.496094</td>\n",
       "      <td>16547.496094</td>\n",
       "      <td>1.123919e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4212 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker           BTC-USD                                            \\\n",
       "Price               Open          High           Low         Close   \n",
       "Date                                                                 \n",
       "2010-01-04           NaN           NaN           NaN           NaN   \n",
       "2010-01-05           NaN           NaN           NaN           NaN   \n",
       "2010-01-06           NaN           NaN           NaN           NaN   \n",
       "2010-01-07           NaN           NaN           NaN           NaN   \n",
       "2010-01-08           NaN           NaN           NaN           NaN   \n",
       "...                  ...           ...           ...           ...   \n",
       "2022-12-27  16919.291016  16959.845703  16642.072266  16717.173828   \n",
       "2022-12-28  16716.400391  16768.169922  16497.556641  16552.572266   \n",
       "2022-12-29  16552.322266  16651.755859  16508.683594  16642.341797   \n",
       "2022-12-30  16641.330078  16643.427734  16408.474609  16602.585938   \n",
       "2022-12-31  16603.673828  16628.986328  16517.519531  16547.496094   \n",
       "\n",
       "Ticker                                        MSFT                          \\\n",
       "Price          Adj Close        Volume        Open        High         Low   \n",
       "Date                                                                         \n",
       "2010-01-04           NaN           NaN   30.620001   31.100000   30.590000   \n",
       "2010-01-05           NaN           NaN   30.850000   31.100000   30.639999   \n",
       "2010-01-06           NaN           NaN   30.879999   31.080000   30.520000   \n",
       "2010-01-07           NaN           NaN   30.629999   30.700001   30.190001   \n",
       "2010-01-08           NaN           NaN   30.280001   30.879999   30.240000   \n",
       "...                  ...           ...         ...         ...         ...   \n",
       "2022-12-27  16717.173828  1.574858e+10  238.699997  238.929993  235.830002   \n",
       "2022-12-28  16552.572266  1.700571e+10  236.889999  239.720001  234.169998   \n",
       "2022-12-29  16642.341797  1.447224e+10  235.649994  241.919998  235.649994   \n",
       "2022-12-30  16602.585938  1.592916e+10  238.210007  239.960007  236.660004   \n",
       "2022-12-31  16547.496094  1.123919e+10         NaN         NaN         NaN   \n",
       "\n",
       "Ticker                  ...         TLT                                     \\\n",
       "Price            Close  ...         Low       Close  Adj Close      Volume   \n",
       "Date                    ...                                                  \n",
       "2010-01-04   30.950001  ...   89.580002   89.809998  59.519924   2829100.0   \n",
       "2010-01-05   30.959999  ...   90.000000   90.389999  59.904362   2841600.0   \n",
       "2010-01-06   30.770000  ...   89.120003   89.180000  59.102425   4099600.0   \n",
       "2010-01-07   30.450001  ...   89.120003   89.330002  59.201794   2793200.0   \n",
       "2010-01-08   30.660000  ...   88.760002   89.290001  59.175323   2910700.0   \n",
       "...                ...  ...         ...         ...        ...         ...   \n",
       "2022-12-27  236.960007  ...  100.010002  100.139999  93.320374  26475700.0   \n",
       "2022-12-28  234.529999  ...   99.349998   99.550003  92.770554  17302900.0   \n",
       "2022-12-29  241.009995  ...   99.790001  100.680000  93.823586  16593000.0   \n",
       "2022-12-30  239.820007  ...   99.370003   99.559998  92.779854  20810200.0   \n",
       "2022-12-31         NaN  ...         NaN         NaN        NaN         NaN   \n",
       "\n",
       "Ticker            VNQ                                                         \n",
       "Price            Open       High        Low      Close  Adj Close     Volume  \n",
       "Date                                                                          \n",
       "2010-01-04  45.220001  45.419998  44.200001  44.549999  24.979658  2408400.0  \n",
       "2010-01-05  44.500000  44.580002  43.930000  44.500000  24.951632  2054200.0  \n",
       "2010-01-06  44.520000  44.840000  44.299999  44.419998  24.906763  2471200.0  \n",
       "2010-01-07  44.459999  45.099998  43.950001  44.900002  25.175903  2091700.0  \n",
       "2010-01-08  44.810001  44.849998  44.180000  44.570000  24.990868  2682000.0  \n",
       "...               ...        ...        ...        ...        ...        ...  \n",
       "2022-12-27  82.709999  82.970001  81.980003  82.709999  76.934006  3961900.0  \n",
       "2022-12-28  82.879997  83.269997  81.180000  81.300003  75.622467  5168000.0  \n",
       "2022-12-29  81.870003  83.260002  81.629997  83.080002  77.278168  5398400.0  \n",
       "2022-12-30  82.480003  82.849998  81.500000  82.480003  76.720062  4897700.0  \n",
       "2022-12-31        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[4212 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_excel(\"PortfolioData.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.to_excel(\"PortfolioData.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Portfolio Optimization (SLSQP)**\n",
    "\n",
    "The portfolio optimization function uses the **SLSQP (Sequential Least Squares Programming)** method to maximize returns while minimizing risk. This approach efficiently handles constraints such as ensuring the portfolio weights sum to 1 and remain within predefined bounds. Additionally, penalties are applied to discourage large weights, promoting diversification, and to maintain stability by accounting for previous weights.\n",
    "\n",
    "The optimization process evaluates a custom objective function that balances return maximization and risk minimization based on the specified λ1 (return weight) and λ2 (risk weight) parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Optimization Function\n",
    "def portfolio_optimization(train_returns, lambda1, lambda2, bounds, constraints, prev_weights=None):\n",
    "  \"\"\"\n",
    "  Perform portfolio optimization using the SLSQP method.\n",
    "\n",
    "  Parameters:\n",
    "    train_returns: DataFrame of asset returns for training.\n",
    "    lambda1: Weight for return maximization.\n",
    "    lambda2: Weight for risk minimization.\n",
    "    bounds: Tuple of bounds for weights.\n",
    "    constraints: Constraints for portfolio weights.\n",
    "    prev_weights: Previous weights (for stability penalty).\n",
    "\n",
    "  Returns:\n",
    "    Optimal portfolio weights as a NumPy array.\n",
    "  \"\"\"\n",
    "  mean_returns = train_returns.mean().values\n",
    "  cov_matrix = train_returns.cov().values\n",
    "\n",
    "  # Define the objective function\n",
    "  def objective(weights):\n",
    "    portfolio_return = np.dot(weights, mean_returns) * 252\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix * 252, weights)))\n",
    "    stability_penalty = 0 if prev_weights is None else 0.01 * np.sum((weights - prev_weights)**2)\n",
    "    penalty = 0.03 * np.sum(weights**2) # Weight penalty\n",
    "    return -(lambda1 * portfolio_return - lambda2 * portfolio_volatility) + penalty + stability_penalty\n",
    "\n",
    "  # Initial guess: equally distributed weights\n",
    "  init_guess = len(tickers) * [1.0 / len(tickers)]\n",
    "\n",
    "  # Perform optimization\n",
    "  result = minimize(\n",
    "    objective,\n",
    "    init_guess,\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints,\n",
    "    options={'maxiter': 1000, 'ftol': 1e-9}\n",
    "  )\n",
    "  return result.x # Optimal weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Risk Metrics**\n",
    "\n",
    "The following metrics were calculated to evaluate portfolio performance:\n",
    "\n",
    "- **Sharpe Ratio**: Risk-adjusted returns.\n",
    "  \n",
    "- **Conditional Value at Risk (CVaR)**: Tail risk metric.\n",
    "\n",
    "- **Maximum Drawdown (MDD)**: Peak-to-trough loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Portfolio Metrics\n",
    "def compute_metrics(weights, returns):\n",
    "  \"\"\"\n",
    "  Compute key metrics for a portfolio: Sharpe Ratio, CVaR, and MDD.\n",
    "\n",
    "  Parameters:\n",
    "    weights: Portfolio weights as a NumPy array.\n",
    "    returns: DataFrame of asset returns.\n",
    "\n",
    "  Returns:\n",
    "    Tuple of Sharpe Ratio, CVaR, and MDD.\n",
    "  \"\"\"\n",
    "  mean_returns = returns.mean().values\n",
    "  cov_matrix = returns.cov().values\n",
    "\n",
    "  portfolio_return = np.dot(weights, mean_returns) * 252\n",
    "  portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix * 252, weights)))\n",
    "  sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility\n",
    "\n",
    "  # Portfolio returns\n",
    "  portfolio_returns = returns.dot(weights)\n",
    "\n",
    "  # Conditional Value at Risk (CVaR)\n",
    "  var_95 = np.percentile(portfolio_returns, 5) # 5% Value at Risk\n",
    "  cvar_95 = portfolio_returns[portfolio_returns <= var_95].mean() # Conditional Value at Risk\n",
    "\n",
    "  # Maximum Drawdown (MDD)\n",
    "  cumulative_returns = (1 + portfolio_returns).cumprod()\n",
    "  rolling_max = cumulative_returns.cummax()\n",
    "  max_drawdown = (rolling_max - cumulative_returns).max()\n",
    "\n",
    "  return sharpe_ratio, cvar_95, max_drawdown\n",
    "\n",
    "def compute_asset_metrics(returns):\n",
    "  \"\"\"\n",
    "  Compute mean return, volatility, and Sharpe ratio for individual assets.\n",
    "  \"\"\"\n",
    "  mean_returns = returns.mean() * 252 \n",
    "  volatilities = returns.std() * np.sqrt(252) \n",
    "  sharpe_ratios = (mean_returns - risk_free_rate) / volatilities\n",
    "\n",
    "  # Combine into a DataFrame\n",
    "  asset_metrics = pd.DataFrame({\n",
    "    'Mean Return': mean_returns,\n",
    "    'Volatility': volatilities,\n",
    "    'Sharpe Ratio': sharpe_ratios\n",
    "  })\n",
    "  return asset_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4 Baseline and Markowitz Portfolio**\n",
    "\n",
    "This section establishes benchmarks for evaluating the performance of the optimized portfolio:\n",
    "\n",
    "- **Baseline Portfolio**: Assumes equal weights for all assets. It serves as a simplistic benchmark to assess the benefits of optimization.\n",
    "  \n",
    "- **Markowitz Portfolio**: Implements the traditional mean-variance optimization method, which seeks to minimize portfolio risk while achieving a target return. This method acts as a comparison to highlight the advantages of the SLSQP approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Portfolio\n",
    "def baseline_metrics(weights, returns):\n",
    "  \"\"\"\n",
    "  Compute performance metrics for the baseline portfolio (equal weights).\n",
    "  \n",
    "  Parameters:\n",
    "    weights (numpy array): Equal weights for all assets.\n",
    "    returns (DataFrame): Asset returns.\n",
    "  \n",
    "  Returns:\n",
    "    Tuple: Sharpe ratio, CVaR, and MDD for the baseline portfolio.\n",
    "  \"\"\"\n",
    "  return compute_metrics(weights, returns)\n",
    "\n",
    "# Markowitz Optimization\n",
    "def markowitz_optimization(train_returns, risk_free_rate, bounds):\n",
    "  \"\"\"\n",
    "  Perform Markowitz mean-variance portfolio optimization.\n",
    "  \n",
    "  Parameters:\n",
    "    train_returns (DataFrame): Asset returns for training.\n",
    "    risk_free_rate (float): Risk-free rate of return.\n",
    "    bounds (tuple): Bounds for portfolio weights.\n",
    "  \n",
    "  Returns:\n",
    "    numpy array: Optimal portfolio weights for the Markowitz method.\n",
    "  \"\"\"\n",
    "  mean_returns = train_returns.mean().values\n",
    "  cov_matrix = train_returns.cov().values\n",
    "  num_assets = len(mean_returns)\n",
    "\n",
    "  # Objective function: Minimize portfolio risk (variance)\n",
    "  def objective(weights):\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return portfolio_volatility\n",
    "\n",
    "  # Constraint: Weights sum to 1\n",
    "  constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]\n",
    "\n",
    "  # Initial guess: equally weighted portfolio\n",
    "  init_guess = num_assets * [1.0 / num_assets]\n",
    "\n",
    "  # Optimize for minimum volatility\n",
    "  result = minimize(objective, init_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "  return result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.5 Hyperparameter Tuning**\n",
    "\n",
    "To optimize the portfolio for varying risk and return preferences, a grid search was conducted over two hyperparameters:\n",
    "\n",
    "- **Lambda1 (Weight for Return Maximization)**: Controls the importance assigned to maximizing returns\n",
    "  \n",
    "- **Lambda2 (Weight for Risk Minimization)**: Adjusts the focus on minimizing portfolio volatility.\n",
    "\n",
    "The grid search uses:\n",
    "\n",
    "- **k-Fold Cross-Validation**: Divides the data into k subsets for training and validation to ensure robust parameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid Search with k-Fold Cross-Validation\n",
    "def k_fold_grid_search(returns, k, lambda1_values, lambda2_values, bounds):\n",
    "  \"\"\"\n",
    "  Perform k-fold cross-validation and grid search for hyperparameter tuning.\n",
    "  \n",
    "  Parameters:\n",
    "    returns (DataFrame): Asset returns.\n",
    "    k (int): Number of folds for cross-validation.\n",
    "    lambda1_values (list): Range of lambda1 values for grid search.\n",
    "    lambda2_values (list): Range of lambda2 values for grid search.\n",
    "    bounds (tuple): Bounds for portfolio weights.\n",
    "  \n",
    "  Returns:\n",
    "    DataFrame: Results of grid search with Sharpe ratio, CVaR, and MDD.\n",
    "  \"\"\"\n",
    "  kf = KFold(n_splits=k, shuffle=False)\n",
    "  results = []\n",
    "  constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1} # Weights sum to 1\n",
    "\n",
    "  for lambda1, lambda2 in product(lambda1_values, lambda2_values):\n",
    "    sharpe_ratios, cvars, mdds = [], [], []\n",
    "    prev_weights = None # For stability penalty\n",
    "\n",
    "    for train_index, val_index in kf.split(returns):\n",
    "      train_returns = returns.iloc[train_index]\n",
    "      val_returns = returns.iloc[val_index]\n",
    "      optimal_weights = portfolio_optimization(train_returns, lambda1, lambda2, bounds, constraints, prev_weights)\n",
    "      sharpe_ratio, cvar_95, max_drawdown = compute_metrics(optimal_weights, val_returns)\n",
    "      sharpe_ratios.append(sharpe_ratio)\n",
    "      cvars.append(cvar_95)\n",
    "      mdds.append(max_drawdown)\n",
    "      prev_weights = optimal_weights\n",
    "\n",
    "    results.append({'lambda1': lambda1, 'lambda2': lambda2, \n",
    "            'sharpe_ratio': np.mean(sharpe_ratios),\n",
    "            'cvar': np.mean(cvars), \n",
    "            'mdd': np.mean(mdds)})\n",
    "\n",
    "  return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter ranges\n",
    "lambda1_values = np.linspace(1.0, 1.5, 10) # Range for lambda1 (return weight)\n",
    "lambda2_values = np.linspace(1.2, 1.8, 10) # Range for lambda2 (risk weight)\n",
    "bounds = tuple((0, 1) for _ in range(len(tickers))) # Portfolio weight bounds\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Run hyperparameter grid search\n",
    "grid_results = k_fold_grid_search(returns, k, lambda1_values, lambda2_values, bounds)\n",
    "\n",
    "# Identify the best parameters\n",
    "best_params = grid_results.loc[grid_results['sharpe_ratio'].idxmax()]\n",
    "\n",
    "# Define Best Lambda Values from Grid Search\n",
    "best_lambda1 = best_params['lambda1']\n",
    "best_lambda2 = best_params['lambda2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.6 Evaluation**\n",
    "\n",
    "Evaluation of portfolio performance is divided into:\n",
    "\n",
    "- **Baseline Portfolio**: Assumes equal weights for all assets as a benchmark.\n",
    "\n",
    "- **Optimized Portfolio**: Uses the best hyperparameters (lambda1, lambda2) for optimization.\n",
    "\n",
    "- **Markowitz Portfolio**: Employs the traditional mean-variance optimization method.\n",
    "\n",
    "- **Sensitivity Analysis**: Assesses the impact of varying lambda1 and lambda2 on portfolio performance.\n",
    "\n",
    "- **Final Implementation**: Combines all insights and applies the best parameters for portfolio construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Baseline Portfolio Evaluation\n",
    "def evaluate_baseline_portfolio(returns):\n",
    "  \"\"\"\n",
    "  Evaluate baseline portfolio metrics with equal weights.\n",
    "  \n",
    "  Parameters:\n",
    "    returns (DataFrame): Asset returns.\n",
    "  \n",
    "  Returns:\n",
    "    dict: Metrics (Sharpe Ratio, CVaR, MDD) for the baseline portfolio.\n",
    "  \"\"\"\n",
    "  weights = np.array([1.0 / len(returns.columns)] * len(returns.columns))\n",
    "  sharpe_ratio, cvar, mdd = compute_metrics(weights, returns)\n",
    "  return {\"weights\": weights, \"sharpe_ratio\": sharpe_ratio, \"cvar\": cvar, \"mdd\": mdd}\n",
    "\n",
    "# Define Backtesting for Optimized Portfolio\n",
    "def backtest_optimized_portfolio(returns, lambda1, lambda2, bounds):\n",
    "  \"\"\"\n",
    "  Perform backtesting for the optimized portfolio using predefined hyperparameters.\n",
    "  \n",
    "  Parameters:\n",
    "    returns (DataFrame): Asset returns.\n",
    "    lambda1 (float): Weight for return maximization.\n",
    "    lambda2 (float): Weight for risk minimization.\n",
    "    bounds (tuple): Bounds for portfolio weights.\n",
    "  \n",
    "  Returns:\n",
    "    dict: Metrics (Sharpe Ratio, CVaR, MDD) and optimal weights.\n",
    "  \"\"\"\n",
    "  optimal_weights = portfolio_optimization(\n",
    "    returns, lambda1, lambda2, bounds, {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n",
    "  )\n",
    "  sharpe_ratio, cvar, mdd = compute_metrics(optimal_weights, returns)\n",
    "  return {\"weights\": optimal_weights, \"sharpe_ratio\": sharpe_ratio, \"cvar\": cvar, \"mdd\": mdd}\n",
    "\n",
    "# Define Markowitz Portfolio Evaluation\n",
    "def evaluate_markowitz_portfolio(returns, bounds, risk_free_rate):\n",
    "  \"\"\"\n",
    "  Evaluate the Markowitz mean-variance optimized portfolio.\n",
    "  \n",
    "  Parameters:\n",
    "    returns (DataFrame): Asset returns.\n",
    "    bounds (tuple): Bounds for portfolio weights.\n",
    "    risk_free_rate (float): Risk-free rate.\n",
    "  \n",
    "  Returns:\n",
    "    dict: Metrics (Sharpe Ratio, CVaR, MDD) and optimal weights for the Markowitz portfolio.\n",
    "  \"\"\"\n",
    "  weights = markowitz_optimization(returns, risk_free_rate, bounds)\n",
    "  sharpe_ratio, cvar, mdd = compute_metrics(weights, returns)\n",
    "  return {\"weights\": weights, \"sharpe_ratio\": sharpe_ratio, \"cvar\": cvar, \"mdd\": mdd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Evaluation\n",
    "def evaluate_all(returns, lambda1, lambda2, bounds, risk_free_rate):\n",
    "  \"\"\"\n",
    "  Evaluate all portfolios: baseline, optimized, and Markowitz.\n",
    "  \n",
    "  Parameters:\n",
    "    returns (DataFrame): Asset returns.\n",
    "    lambda1 (float): Weight for return maximization for the optimized portfolio.\n",
    "    lambda2 (float): Weight for risk minimization for the optimized portfolio.\n",
    "    bounds (tuple): Bounds for portfolio weights.\n",
    "    risk_free_rate (float): Risk-free rate.\n",
    "  \n",
    "  Returns:\n",
    "    dict: Results for all portfolios.\n",
    "  \"\"\"\n",
    "  # Backtesting for Optimized Portfolio\n",
    "  optimized_results = backtest_optimized_portfolio(\n",
    "    returns, lambda1, lambda2, bounds\n",
    "  )\n",
    "  print(\"Optimized Portfolio (SLSQP):\\n\",\n",
    "     f\"Sharpe Ratio: {optimized_results['sharpe_ratio']:.3f}, \"\n",
    "     f\"CVaR: {optimized_results['cvar']:.3f}, \"\n",
    "     f\"MDD: {optimized_results['mdd']:.3f}\")\n",
    "\n",
    "  # Evaluate Markowitz Portfolio\n",
    "  markowitz_results = evaluate_markowitz_portfolio(returns, bounds, risk_free_rate)\n",
    "  print(\"\\nMarkowitz Portfolio (Traditional):\\n\",\n",
    "     f\"Sharpe Ratio: {markowitz_results['sharpe_ratio']:.3f}, \"\n",
    "     f\"CVaR: {markowitz_results['cvar']:.3f}, \"\n",
    "     f\"MDD: {markowitz_results['mdd']:.3f}\")\n",
    "\n",
    "  # Evaluate Baseline Portfolio\n",
    "  baseline_results = evaluate_baseline_portfolio(returns)\n",
    "  print(\"\\nBaseline Portfolio (Equal-Weighted):\\n\",\n",
    "     f\"Sharpe Ratio: {baseline_results['sharpe_ratio']:.3f}, \"\n",
    "     f\"CVaR: {baseline_results['cvar']:.3f}, \"\n",
    "     f\"MDD: {baseline_results['mdd']:.3f}\")\n",
    "\n",
    "  return {\n",
    "    \"baseline\": baseline_results,\n",
    "    \"optimized\": optimized_results,\n",
    "    \"markowitz\": markowitz_results,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(returns, evaluation_results):\n",
    "  \"\"\"\n",
    "  Plot cumulative returns for Optimized, Markowitz, and Baseline portfolios.\n",
    "  \n",
    "  Parameters:\n",
    "    returns (DataFrame): Daily asset returns.\n",
    "    evaluation_results (dict): Results containing weights for all portfolios.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(12, 6))\n",
    "\n",
    "  # Optimized portfolio\n",
    "  optimized_weights = evaluation_results['optimized']['weights']\n",
    "  optimized_portfolio_returns = returns.dot(optimized_weights)\n",
    "  optimized_cumulative_returns = (1 + optimized_portfolio_returns).cumprod()\n",
    "  plt.plot(optimized_cumulative_returns, label=\"Optimized Portfolio (SLSQP)\", color='blue')\n",
    "\n",
    "  # Markowitz portfolio\n",
    "  markowitz_weights = evaluation_results['markowitz']['weights']\n",
    "  markowitz_portfolio_returns = returns.dot(markowitz_weights)\n",
    "  markowitz_cumulative_returns = (1 + markowitz_portfolio_returns).cumprod()\n",
    "  plt.plot(markowitz_cumulative_returns, label=\"Markowitz Portfolio\", color='orange')\n",
    "\n",
    "  # Baseline portfolio\n",
    "  baseline_weights = evaluation_results['baseline']['weights']\n",
    "  baseline_portfolio_returns = returns.dot(baseline_weights)\n",
    "  baseline_cumulative_returns = (1 + baseline_portfolio_returns).cumprod()\n",
    "  plt.plot(baseline_cumulative_returns, label=\"Baseline Portfolio\", color='green')\n",
    "\n",
    "  # Add labels, title, and legend\n",
    "  plt.title(\"Cumulative Returns Comparison\")\n",
    "  plt.xlabel(\"Time\")\n",
    "  plt.ylabel(\"Cumulative Returns\")\n",
    "  plt.legend()\n",
    "  plt.grid()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis(returns, lambda1_range, lambda2_range, bounds):\n",
    "  \"\"\"\n",
    "  Perform sensitivity analysis for lambda1 and lambda2.\n",
    "  \n",
    "  Parameters:\n",
    "    returns (DataFrame): Asset returns.\n",
    "    lambda1_range (list): Range of lambda1 values to test.\n",
    "    lambda2_range (list): Range of lambda2 values to test.\n",
    "    bounds (tuple): Bounds for portfolio weights.\n",
    "  \n",
    "  Returns:\n",
    "    DataFrame: Sensitivity analysis results with Sharpe Ratio, CVaR, and MDD.\n",
    "  \"\"\"\n",
    "  results = []\n",
    "  constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n",
    "\n",
    "  for lambda1, lambda2 in product(lambda1_range, lambda2_range):\n",
    "    optimal_weights = portfolio_optimization(returns, lambda1, lambda2, bounds, constraints)\n",
    "    sharpe_ratio, cvar, mdd = compute_metrics(optimal_weights, returns)\n",
    "    results.append({'lambda1': lambda1, 'lambda2': lambda2, \n",
    "            'sharpe_ratio': sharpe_ratio, 'cvar': cvar, 'mdd': mdd})\n",
    "  \n",
    "  return pd.DataFrame(results)\n",
    "\n",
    "# Define the range for sensitivity analysis\n",
    "lambda1_range = np.linspace(1.0, 1.5, 10)\n",
    "lambda2_range = np.linspace(1.2, 1.8, 10)\n",
    "\n",
    "# Perform Sensitivity Analysis\n",
    "sensitivity_results = sensitivity_analysis(returns, lambda1_range, lambda2_range, bounds)\n",
    "\n",
    "# Visualize the Sensitivity Analysis\n",
    "def plot_sensitivity_analysis(sensitivity_results):\n",
    "  \"\"\"\n",
    "  Visualize the sensitivity of Sharpe Ratio to lambda1 and lambda2 values.\n",
    "  \n",
    "  Parameters:\n",
    "    sensitivity_results (DataFrame): Sensitivity analysis results.\n",
    "  \"\"\"\n",
    "  pivot_sharpe = sensitivity_results.pivot(index='lambda1', columns='lambda2', values='sharpe_ratio')\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  sns.heatmap(pivot_sharpe, annot=True, cmap='coolwarm', fmt=\".3f\")\n",
    "  plt.title(\"Sensitivity of Sharpe Ratio to λ1 and λ2\")\n",
    "  plt.xlabel(\"λ2 (Risk Weight)\")\n",
    "  plt.ylabel(\"λ1 (Return Weight)\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_implementation(returns, best_lambda1, best_lambda2, bounds, risk_free_rate):\n",
    "  \"\"\"\n",
    "  Perform the final portfolio optimization and evaluation.\n",
    "  \n",
    "  Parameters:\n",
    "    returns (DataFrame): Asset returns.\n",
    "    best_lambda1 (float): Best value for lambda1 (return weight).\n",
    "    best_lambda2 (float): Best value for lambda2 (risk weight).\n",
    "    bounds (tuple): Bounds for portfolio weights.\n",
    "    risk_free_rate (float): Risk-free rate.\n",
    "  \n",
    "  Returns:\n",
    "    dict: Final portfolio weights and performance metrics.\n",
    "  \"\"\"\n",
    "  # Optimize the portfolio with the best parameters\n",
    "  optimal_weights = portfolio_optimization(\n",
    "    returns, best_lambda1, best_lambda2, bounds, {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n",
    "  )\n",
    "  sharpe_ratio, cvar, mdd = compute_metrics(optimal_weights, returns)\n",
    "\n",
    "  print(\"Final Portfolio Weights:\")\n",
    "  for ticker, weight in zip(returns.columns, optimal_weights):\n",
    "    print(f\"{ticker}: {weight:.2%}\")\n",
    "\n",
    "  print(\"\\nFinal Performance Metrics:\")\n",
    "  print(f\"Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "  print(f\"CVaR: {cvar:.3f}\")\n",
    "  print(f\"MDD: {mdd:.3f}\")\n",
    "\n",
    "  return {\"weights\": optimal_weights, \"sharpe_ratio\": sharpe_ratio, \"cvar\": cvar, \"mdd\": mdd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.7 Rolling-Window Backtesting**\n",
    "\n",
    "Rolling-window backtesting assesses the portfolio’s adaptability to dynamic market conditions. This method recalibrates portfolio weights over:\n",
    "\n",
    "- **Rolling Period**s: Fixed window sizes (e.g., 252 days for one year) to simulate real-time portfolio management.\n",
    "  \n",
    "- **Step Sizes**: Smaller intervals (e.g., 21 days) between recalibrations to maintain responsiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling-Window Backtesting\n",
    "def rolling_window_backtesting(returns, window_size, step_size, lambda1, lambda2, bounds):\n",
    "  \"\"\"\n",
    "  Perform rolling-window backtesting of the portfolio.\n",
    "  \n",
    "  Parameters:\n",
    "    returns (DataFrame): Asset returns.\n",
    "    window_size (int): Size of the rolling window (in days).\n",
    "    step_size (int): Step size for the rolling window (in days).\n",
    "    lambda1 (float): Weight for portfolio return.\n",
    "    lambda2 (float): Weight for portfolio risk.\n",
    "    bounds (tuple): Bounds for portfolio weights.\n",
    "  \n",
    "  Returns:\n",
    "    metrics (DataFrame): Sharpe ratio, CVaR, and MDD for each window.\n",
    "    weights (list): Optimal weights for each rolling window.\n",
    "  \"\"\"\n",
    "  metrics = []\n",
    "  weights = []\n",
    "  constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1} # Weights sum to 1\n",
    "  \n",
    "  for start in range(0, len(returns) - window_size, step_size):\n",
    "    end = start + window_size\n",
    "    train_returns = returns.iloc[start:end]\n",
    "    optimal_weights = portfolio_optimization(train_returns, lambda1, lambda2, bounds, constraints)\n",
    "    weights.append(optimal_weights)\n",
    "    sharpe_ratio, cvar, mdd = compute_metrics(optimal_weights, train_returns)\n",
    "    metrics.append({'start_date': returns.index[start], \n",
    "            'end_date': returns.index[end - 1], \n",
    "            'Sharpe_Ratio': sharpe_ratio, \n",
    "            'CVaR': cvar, \n",
    "            'MDD': mdd})\n",
    "  \n",
    "  return pd.DataFrame(metrics), weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results\n",
    "\n",
    "This section synthesizes key findings from the methodology. Each part of the analysis is presented with relevant figures and metrics to explain the portfolio’s performance and adaptability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Performance Metrics Across Portfolios**\n",
    "\n",
    "The performance metrics—Sharpe Ratio, CVaR, and Maximum Drawdown (MDD)—highlighted the superior risk-adjusted returns and resilience of the optimized portfolio compared to the baseline and Markowitz portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Perform Evaluation\n",
    "evaluation_results = evaluate_all(returns, best_lambda1, best_lambda2, bounds, risk_free_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "- The optimized portfolio achieved the highest Sharpe Ratio (1.362), indicating strong risk-adjusted returns. The CVaR of -0.016 shows a controlled tail risk, while the MDD of 0.211 reflects minimal peak-to-trough losses. This demonstrates the portfolio’s ability to balance return maximization and risk minimization effectively\n",
    "\n",
    "- The Markowitz portfolio achieved better risk-adjusted returns compared to the baseline portfolio but lagged behind the optimized portfolio. The MDD (0.184) is slightly better than the optimized portfolio, reflecting improved stability. However, its lower Sharpe Ratio (1.070) indicates suboptimal return generation compared to the SLSQP method\n",
    "\n",
    "- The baseline portfolio, with equal weights for all assets, displayed lower risk-adjusted returns compared to the optimized portfolio. The significantly higher CVaR (-0.033) and MDD (0.694) highlight its vulnerability to extreme losses, emphasizing the limitations of equal-weighting strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Cumulative Returns Comparison**\n",
    "\n",
    "The cumulative returns demonstrate the practical advantage of the SLSQP approach in maximizing returns while minimizing risks across different market conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Cumulative Returns\n",
    "plot_cumulative_returns(returns, evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** \n",
    "\n",
    "- The **Optimized Portfolio (SLSQP )** outperformed both the **Markowitz Portfolio** and **Baseline Portfolio** in cumulative returns, highlighting its superior performance across the evaluation period\n",
    "\n",
    "- The optimized portfolio exhibited resilience during market drawdowns, such as the COVID-19-induced market crash in 2020, recovering faster and maintaining lower volatility\n",
    "\n",
    "- The baseline portfolio lagged significantly, reinforcing the value of optimization methods in portfolio construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Sensitivity Analysis**\n",
    "\n",
    "The sensitivity analysis validated the choice of hyperparameters used in the portfolio optimization, ensuring a balanced trade-off between returns and risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Sensitivity Analysis\n",
    "plot_sensitivity_analysis(sensitivity_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "\n",
    "- The sensitivity analysis explored the impact of varying **λ1 (return weight)** and **λ2 (risk weight)** on the Sharpe Ratio, providing insights into the model’s responsiveness to these parameters.\n",
    "\n",
    "- Higher **λ1** values emphasized return maximization, resulting in improved Sharpe Ratios, while increased **λ2** values reflected a greater focus on risk mitigation.\n",
    "\n",
    "- Although the heatmap suggests optimal performance around **λ1 = 1.2** and **λ2 = 1.4**, the grid search selected **λ1 = 1** and **λ2 = 1.8** as the best parameters based on averaged performance across multiple cross-validation folds. This highlights the robustness of the chosen hyperparameters for generalizability across market conditions.\n",
    "\n",
    "- The heatmap complements the grid search by identifying regions of strong performance, validating that the selected hyperparameters lie within a high-performing range. This dual perspective ensures both precision and broader applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.4 Final Portfolio Implementation Results**\n",
    "\n",
    "The final portfolio allocation reflected a well-diversified strategy with robust performance across risk-adjusted metrics, consistent with the project’s objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Final Implementation\n",
    "final_results = final_implementation(returns, best_lambda1, best_lambda2, bounds, risk_free_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "The optimized portfolio allocates significant weights to assets with strong risk-adjusted returns and stabilizing characteristics:\n",
    "\n",
    "**High Allocations**:\n",
    "\n",
    "  - **MSFT (21.51%)**: Strong performance with high Sharpe Ratio.\n",
    "    \n",
    "  - **DBC (28.51%)**: Provides diversification benefits and robust risk-return trade-offs.\n",
    " \n",
    "    \n",
    "  - **TLT (29.13%)** and **GLD (19.08%)**: Stabilizing assets that mitigate risk, especially during volatile periods.\n",
    "\n",
    "**Low or Zero Allocations**:\n",
    "\n",
    "  - **AAPL (0.00%)** and **GOOGL (0.00%)**: Likely deprioritized due to their correlations with other assets or less favorable risk-adjusted returns\n",
    "\n",
    "  - **ETH-USD (0.00%)**: High volatility and poor risk-return trade-off make it unsuitable for inclusion\n",
    "    \n",
    "  - **VNQ (0.43%)**: Minimal allocation suggests it provides limited diversification benefits in the current portfolio\n",
    "\n",
    "The portfolio reflects a balance between assets with strong performance potential and those that stabilize overall risk, achieving a high Sharpe Ratio while maintaining relatively low Conditional Value at Risk (CVaR) and Maximum Drawdown (MDD). This allocation strategy ensures effective diversification and risk management while maximizing returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display asset-level metrics\n",
    "asset_metrics = compute_asset_metrics(returns)\n",
    "print(\"\\nAsset-Level Metrics:\\n\")\n",
    "asset_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** \n",
    "\n",
    "1. **High Allocations in the Optimized Portfolio**\n",
    "\n",
    "   - **MSFT (21.51%)**: Has the highest Sharpe Ratio (**1.065**), indicating strong risk-adjusted returns\n",
    "     \n",
    "   - **DBC (28.51%)**: A well-diversified asset with a relatively high Sharpe Ratio (**0.871**) and lower volatility (**0.185**)\n",
    "     \n",
    "   - **GLD (19.08%)** and **TLT (29.13%)**: Though their Sharpe Ratios are lower (**0.606** and **0.338**, respectively), they are stabilizing assets with low volatility, making them valuable for risk reduction\n",
    "\n",
    "2. **Low or Zero Allocations**\n",
    "\n",
    "   - **AAPL (0.00%)** and **GOOGL (0.00%)**: Despite reasonable Sharpe Ratios (**0.726** and **0.619**), these assets are likely excluded due to high correlations with **MSFT**, offering redundant exposure without sufficient diversification benefits.\n",
    "     \n",
    "   - **BTC-USD (1.34%)** and **ETH-USD (0.00%)**: Cryptocurrencies exhibit high volatility (**0.676** and **0.844**) and lower Sharpe Ratios (**0.486** and **0.339**), reducing their attractiveness as stable contributors to the portfolio.\n",
    "\n",
    "3. **Moderate Allocation**\n",
    "\n",
    "   \n",
    "   - **VNQ (0.43%)**: Its Sharpe Ratio (**0.623**) is reasonable, but its return and volatility metrics are less compelling compared to other included assets, resulting in a minimal allocation.\n",
    "\n",
    "The optimized portfolio allocates weights based on a balance between maximizing risk-adjusted returns (Sharpe Ratio) and minimizing volatility. High-weighted assets, like **MSFT** and **DBC**, dominate due to their strong performance, while low-volatility assets, like **GLD** and **TLT**, contribute to stability. Conversely, assets with higher risk or redundant correlations, like **AAPL**, **GOOGL**, and **ETH-USD**, are deprioritized to enhance overall diversification and portfolio performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = returns.corr()\n",
    "\n",
    "# Analyze excluded assets\n",
    "excluded_assets = ['AAPL', 'GOOGL', 'ETH-USD'] # Assets excluded in the optimized portfolio\n",
    "correlations_to_others = correlation_matrix[excluded_assets].drop(index=excluded_assets)\n",
    "\n",
    "print(\"\\nCorrelations of Excluded Assets to Other Assets:\\n\")\n",
    "correlations_to_others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excluded Assets:**\n",
    "\n",
    "1. **ETH-USD and BTC-USD**:\n",
    "\n",
    "   - **Strong Correlation**: The high correlation between **BTC-USD** and **ETH-USD** (**0.792**) indicates redundancy in their risk-return profiles. This reduces the diversification benefits of including both, leading to the exclusion of **ETH-USD**.\n",
    "   \n",
    "2. **GOOGL and MSFT**:\n",
    "\n",
    "   - **Tech Correlation**: **GOOGL**'s strong correlation with **MSFT** (**0.796**) diminishes its unique contribution to the portfolio. Since **MSFT** has a higher Sharpe Ratio, it is prioritized over **GOOGL**.\n",
    "\n",
    "3. **AAPL**:\n",
    "\n",
    "   - **Redundancy with MSFT and VNQ**: **AAPL** exhibits moderate correlations with **MSFT** (**0.760**) and **VNQ** (**0.545**). Combined with its lower Sharpe Ratio, this makes it less favorable for inclusion.\n",
    "\n",
    "**Diversified Portfolio:**\n",
    "\n",
    "The inclusion of assets with complementary risk-return profiles, such as:\n",
    "\n",
    "- **MSFT**: A high-performing tech stock with a strong Sharpe Ratio.\n",
    "  \n",
    "- **TLT**: A stabilizing asset with low volatility and negative correlations with equities.\n",
    "\n",
    "- **DBC**: A commodity-focused asset providing diversification benefits with minimal correlations to other included assets.\n",
    "\n",
    "This balanced selection enhances the overall portfolio performance, maximizing returns while minimizing risks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.5 Rolling-Window Backtesting**\n",
    "\n",
    "Rolling-window backtesting highlighted the portfolio’s adaptability to market conditions and its ability to sustain superior risk-adjusted returns over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "window_size = 252 # 1 year\n",
    "step_size = 21 # 1 month\n",
    "rolling_metrics, rolling_weights = rolling_window_backtesting(returns, window_size, step_size, \n",
    "                               best_params['lambda1'], \n",
    "                               best_params['lambda2'], bounds)\n",
    "\n",
    "# Display Results\n",
    "print(\"Rolling-Window Metrics:\\n\")\n",
    "rolling_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Rolling Metrics\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "ax1.plot(rolling_metrics['start_date'], rolling_metrics['Sharpe_Ratio'], label='Sharpe Ratio', color='blue')\n",
    "ax1.plot(rolling_metrics['start_date'], rolling_metrics['MDD'], label='MDD', color='green')\n",
    "ax1.set_ylabel(\"Sharpe Ratio / MDD\", color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(rolling_metrics['start_date'], rolling_metrics['CVaR'], label='CVaR', color='red', linestyle='dashed')\n",
    "ax2.set_ylabel(\"CVaR\", color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "fig.suptitle(\"Rolling Portfolio Metrics Over Time\")\n",
    "fig.tight_layout()\n",
    "fig.legend(loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Rolling Weights\n",
    "rolling_weights_df = pd.DataFrame(rolling_weights, columns=tickers)\n",
    "rolling_weights_df['start_date'] = rolling_metrics['start_date']\n",
    "rolling_weights_df.set_index('start_date', inplace=True)\n",
    "rolling_weights_df.plot(figsize=(12, 6), title='Rolling Portfolio Weights')\n",
    "plt.xlabel(\"Start Date\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.legend(title=\"Assets\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** \n",
    "\n",
    "- **Sharpe Ratio Trends:** Rolling Sharpe Ratios showed variability over time, peaking during favorable market conditions and dropping during downturns like the COVID-19 crash. \n",
    "\n",
    "- **CVaR and MDD Trends:** Tail risk and drawdowns were well-controlled, demonstrating the portfolio's resilience to market fluctuations. \n",
    "\n",
    "- **Dynamic Weights:** Portfolio weights adjusted dynamically across time windows, adapting to changing market conditions and ensuring balanced risk-return profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discussion and Conclusion\n",
    "\n",
    "This section summarizes the key takeaways from the results, highlights the challenges encountered during the project, and outlines future improvements and potential refinements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Did You Learn from Your Results?**\n",
    "\n",
    "- The portfolio optimization model using the SLSQP method (Sequential Least Squares Programming Algorithm) demonstrated its ability to effectively balance returns and risks, achieving superior performance metrics compared to both the baseline (equal-weighted portfolio) and the traditional Markowitz mean-variance optimization:\n",
    "\n",
    "    - **Optimized Portfolio** (SLSQP): Sharpe Ratio = **1.362**, CVaR = **-0.016**, MDD = **0.211**\n",
    "\n",
    "    - **Markowitz Portfolio**: Sharpe Ratio = **1.070**, CVaR = **-0.014**, MDD = **0.184**\n",
    "\n",
    "    - **Baseline Portfolio**: Sharpe Ratio = **0.867**, CVaR = **-0.033**, MDD = **0.694**\n",
    "\n",
    "- Sensitivity analysis showed how varying **λ1** (return weight) and **λ2** (risk weight) impacted portfolio performance:\n",
    "\n",
    "    - Higher **λ1** values prioritized returns, improving Sharpe Ratios.\n",
    "\n",
    "    - The chosen hyperparameters **λ1 = 1.0** and **λ2 = 1.8** achieved robust performance across cross-validation folds and aligned with the general high-performing range on the heatmap.\n",
    "\n",
    "- Rolling-window backtesting revealed the adaptability of the optimization model under varying market conditions:\n",
    "\n",
    "    - Sharpe Ratios fluctuated during high-volatility periods (e.g., COVID-19 downturn) but remained relatively stable compared to the baseline.\n",
    "\n",
    "    - Maximum Drawdowns (MDD) were consistently controlled, reflecting the model’s ability to mitigate risks effectively.\n",
    "\n",
    "- Asset-level analysis revealed that certain assets (e.g., **GOOGL**, **AAPL**, **ETH-USD**) were excluded from the final portfolio due to low Sharpe Ratios or high correlations with other included assets, which reduced their diversification value.\n",
    "\n",
    "**Obstacles Encountered**\n",
    "\n",
    "1. **Class Imbalance in Asset Returns**: Certain assets exhibited extreme volatility (e.g., cryptocurrencies), making it challenging to balance their inclusion in the portfolio. This was addressed by penalizing large weights in the optimization function.\n",
    "\n",
    "2. **Hyperparameter Sensitivity**: Initial grid search results were sometimes overly sensitive to specific **λ1** and **λ2** values. This was mitigated by using cross-validation to select hyperparameters that generalized well across different training folds.\n",
    "\n",
    "3. **Rolling-Window Computational Overheads**: Performing rolling-window backtesting on large datasets with multiple assets required significant computational resources. Code optimizations (e.g., vectorization) helped reduce runtime.\n",
    "\n",
    "**What Would You Do Differently Next Time?**\n",
    "\n",
    "1. **Include More Diverse Asset Classes**: Expanding the dataset to include additional asset classes, such as real estate or commodities, would further test the model's adaptability to different economic conditions.\n",
    "\n",
    "2. **Integrate Advanced Risk Metrics**: Incorporate additional risk measures, such as Value at Risk (VaR) at multiple confidence levels or Sortino Ratio, to provide a more comprehensive evaluation of portfolio performance.\n",
    "\n",
    "3. **Explore Machine Learning Models**: Incorporate reinforcement learning or neural networks to model asset weight allocations dynamically, potentially outperforming traditional optimization techniques.\n",
    "\n",
    "4. **Analyze Economic Context**: Study the portfolio's behavior during specific historical economic events (e.g., 2008 financial crisis, 2020 COVID-19 pandemic) to draw deeper insights into its adaptability.\n",
    "\n",
    "**Quantitative Answers to Questions**\n",
    "\n",
    "**Did the optimized portfolio outperform traditional methods?**\n",
    "\n",
    " - Yes, the SLSQP optimization method yielded a Sharpe Ratio of **1.362**, significantly outperforming the Markowitz portfolio (**1.070**) and the equal-weighted baseline (**0.867**).\n",
    "\n",
    "**How did the portfolio perform during volatile periods?**\n",
    "\n",
    " - Rolling-window backtesting showed that the optimized portfolio maintained relatively stable Sharpe Ratios and lower drawdowns during periods of market turbulence, such as the COVID-19 downturn.\n",
    "\n",
    "**Were the chosen hyperparameters effective?**\n",
    "\n",
    " - Yes, the sensitivity analysis confirmed that **λ1 = 1.0** and **λ2 = 1.8** fell within the high-performing range of hyperparameters, as demonstrated by the heatmap and cross-validation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project successfully demonstrated that the SLSQP method could optimize a portfolio by balancing returns and risks more effectively than traditional methods. The model not only achieved superior performance metrics but also exhibited robustness under varying economic conditions. While there are opportunities to enhance the methodology (e.g., using machine learning models or integrating broader asset classes), this study underscores the potential of advanced optimization techniques in financial decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References\n",
    "\n",
    "This section serves to properly attribute all sources, tools, and methodologies that were utilized or referenced during the course of the project. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Historical financial data was sourced using the [Yahoo Finance API](https://pypi.org/project/yfinance/).\n",
    "\n",
    "2. Nocedal, J., & Wright, S. J. (2006). *Numerical Optimization*. Springer. (Reference for the optimization algorithms)\n",
    "\n",
    "3. Scipy documentation: [https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html)\n",
    "\n",
    "3. Sharpe, W. F. (1994). *The Sharpe Ratio*. Journal of Portfolio Management, 21(1), 49–58. (Source for Sharpe Ratio calculations.)\n",
    "\n",
    "4. Rockafellar, R. T., & Uryasev, S. (2000). *Optimization of Conditional Value-at-Risk*. Journal of Risk, 2(3), 21–41. (Source for CVaR calculations.)\n",
    "\n",
    "5. This project benefited from assistance provided by OpenAI's ChatGPT for structuring, debugging, and refining code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
